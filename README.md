
---

# Adaptive RAG Pipeline ğŸ¦œğŸ”—

An advanced **Retrieval-Augmented Generation (RAG)** system built with LangGraph, featuring:

* âœ… **Adaptive RAG** â€” Intelligent routing between vectorstore and web search
* âœ… **Self RAG** â€” Hallucination detection and answer quality verification
* âœ… **Corrective RAG** â€” Document relevance evaluation before generation
* âœ… **Multi-turn conversations** â€” Conversation memory support

![Graph](graph.png)

---

## ğŸš€ Features

### 1ï¸âƒ£ Intelligent Routing (Adaptive RAG)

The system dynamically decides whether to use the vectorstore or web search based on the user's query.

### 2ï¸âƒ£ Document Evaluation (Corrective RAG)

Retrieved documents are evaluated for relevance before generating the final answer.

### 3ï¸âƒ£ Hallucination Detection (Self RAG)

The generated response is checked to ensure it is grounded, relevant, and free from hallucinations.

### 4ï¸âƒ£ Multi-turn Conversations

Conversation history is maintained using a checkpointer, enabling contextual follow-up questions.

---

## ğŸ“‹ Prerequisites

* Python 3.13+
* Poetry (for dependency management)
* OpenAI API Key
* Tavily API Key (for web search)

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/adaptive-rag-pipeline.git
cd adaptive-rag-pipeline
```

### 2ï¸âƒ£ Install Dependencies

```bash
poetry install
```

### 3ï¸âƒ£ Configure Environment Variables

Copy the example environment file and add your API keys:

```bash
cp .env.example .env
```

Then edit the `.env` file:

```bash
OPENAI_API_KEY=sk-...
TAVILY_API_KEY=tvly-...
```

### 4ï¸âƒ£ Run Ingestion (One-time setup)

Load documents into the vector store:

```bash
poetry run python ingestion.py
```

### 5ï¸âƒ£ Run the Application

```bash
poetry run python main.py
```

---

## ğŸ—ï¸ Project Structure

```
adaptive-rag-pipeline/
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ chains/          # LLM chains (grading, generation, etc.)
â”‚   â”œâ”€â”€ nodes/           # Graph nodes (retrieve, generate, web_search, etc.)
â”‚   â”œâ”€â”€ state.py         # State definition
â”‚   â”œâ”€â”€ consts.py        # Constants
â”‚   â””â”€â”€ graph.py         # Main graph construction
â”œâ”€â”€ ingestion.py         # Vector store ingestion
â”œâ”€â”€ main.py              # Entry point
â”œâ”€â”€ graph.png            # Graph visualization
â”œâ”€â”€ pyproject.toml       # Poetry configuration
â””â”€â”€ README.md            # This file
```

---

## ğŸ¯ Usage

### Basic Example

```python
from graph.graph import app

result = app.invoke({"question": "What is agent memory?"})
print(result["generation"])
```

### Using a ChatSession Wrapper

```python
from graph.graph import app

class ChatSession:
    def __init__(self, thread_id: str):
        self.config = {"configurable": {"thread_id": thread_id}}
    
    def ask(self, question: str):
        result = app.invoke(
            {"question": question},
            config=self.config
        )
        return result["generation"]

# Usage
session = ChatSession(thread_id="user_123")
print(session.ask("What is RAG?"))
print(session.ask("Tell me more"))  # Understands conversation history!
```

---

## ğŸ§ª Running Tests

```bash
poetry run pytest -v
```

---

## ğŸ“Š System Workflow

```
User Question
    â†“
Router (Vectorstore or Web Search?)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       â”‚
Vectorstore         Web Search
    â†“                   â†“
Grade Documents         â”‚
    â†“                   â”‚
â”Œâ”€â”€â”€â”´â”€â”€â”€â”               â”‚
â”‚       â”‚               â”‚
Relevant  Not Relevant â”€â”˜
â”‚           â”‚
Generate    Web Search â†’ Generate
    â†“
Check Hallucination
    â†“
Check Relevance to Question
    â†“
Final Answer âœ…
```

---

## ğŸ› ï¸ Technologies Used

* LangChain â€” Core LLM framework
* LangGraph â€” Graph-based workflow orchestration
* OpenAI GPT-4 â€” Language model
* Chroma â€” Vector database
* Tavily â€” Web search API
* HuggingFace Embeddings â€” Text-to-vector embedding model

---

## ğŸ“ License

MIT License â€” Free to use and modify.

---

## ğŸ¤ Contributing

Pull requests and issues are welcome!

---

## ğŸ“§ Contact

* GitHub: [@YOUR_USERNAME](https://github.com/YOUR_USERNAME)
* Email: [your.email@example.com](mailto:your.email@example.com)

---

**Built with â¤ï¸ by [Tina Rostami]**

---

